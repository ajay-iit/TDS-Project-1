{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KWpAI_-aypro",
        "outputId": "7553b4a0-a865-47e1-e09c-aa33b81031c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Page 1, Users found: 30\n",
            "Page 2, Users found: 30\n",
            "Page 3, Users found: 30\n",
            "Page 4, Users found: 30\n",
            "Page 5, Users found: 30\n",
            "Page 6, Users found: 30\n",
            "Page 7, Users found: 30\n",
            "Page 8, Users found: 30\n",
            "Page 9, Users found: 30\n",
            "Page 10, Users found: 30\n",
            "Page 11, Users found: 30\n",
            "Page 12, Users found: 30\n",
            "Page 13, Users found: 30\n",
            "Page 14, Users found: 30\n",
            "Page 15, Users found: 30\n",
            "Page 16, Users found: 21\n",
            "Page 17, Users found: 0\n",
            "Total users collected: 471\n",
            "Data saved to users.csv\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "\n",
        "# GitHub API token for authentication\n",
        "TOKEN = \"My_Token\"\n",
        "HEADERS = {\"Authorization\": f\"token {TOKEN}\"}\n",
        "\n",
        "# API base URL for users in Austin with over 100 followers\n",
        "BASE_URL = \"https://api.github.com/search/users\"\n",
        "USER_DETAILS_URL = \"https://api.github.com/users/\"\n",
        "\n",
        "# Initialize an empty list to store user data\n",
        "user_data = []\n",
        "\n",
        "# Pagination loop\n",
        "page = 1\n",
        "while True:\n",
        "    # Search query\n",
        "    params = {\n",
        "        \"q\": \"location:Austin followers:>100\",\n",
        "        \"per_page\": 30,\n",
        "        \"page\": page\n",
        "    }\n",
        "    response = requests.get(BASE_URL, headers=HEADERS, params=params)\n",
        "\n",
        "    # Check for errors in response\n",
        "    if response.status_code != 200:\n",
        "        print(\"Error:\", response.status_code, response.text)\n",
        "        break\n",
        "\n",
        "    users = response.json().get('items', [])\n",
        "    print(f\"Page {page}, Users found: {len(users)}\")  # Debugging: check user count\n",
        "\n",
        "    # Stop if there are no more users\n",
        "    if not users:\n",
        "        break\n",
        "\n",
        "    # Fetch detailed information for each user\n",
        "    for user in users:\n",
        "        user_response = requests.get(USER_DETAILS_URL + user['login'], headers=HEADERS)\n",
        "\n",
        "        # Check for errors in user detail response\n",
        "        if user_response.status_code != 200:\n",
        "            print(\"Error fetching user:\", user['login'], user_response.text)\n",
        "            continue\n",
        "\n",
        "        user_info = user_response.json()\n",
        "\n",
        "        # Format data as per specifications\n",
        "        user_data.append({\n",
        "            \"login\": user_info.get(\"login\", \"\"),\n",
        "            \"name\": user_info.get(\"name\", \"\"),\n",
        "            \"company\": (user_info.get(\"company\", \"\").replace('@', '').strip().upper()\n",
        "                        if user_info.get(\"company\") else \"\"),\n",
        "            \"location\": user_info.get(\"location\", \"\"),\n",
        "            \"email\": user_info.get(\"email\", \"\"),\n",
        "            \"hireable\": \"true\" if user_info.get(\"hireable\") else \"false\" if user_info.get(\"hireable\") is not None else \"\",\n",
        "            \"bio\": user_info.get(\"bio\", \"\"),\n",
        "            \"public_repos\": user_info.get(\"public_repos\", 0),\n",
        "            \"followers\": user_info.get(\"followers\", 0),\n",
        "            \"following\": user_info.get(\"following\", 0),\n",
        "            \"created_at\": user_info.get(\"created_at\", \"\")\n",
        "        })\n",
        "\n",
        "    # Move to the next page\n",
        "    page += 1\n",
        "\n",
        "# Check if user_data is populated\n",
        "print(\"Total users collected:\", len(user_data))\n",
        "\n",
        "# Convert list of dictionaries to DataFrame and check for data presence before saving\n",
        "if user_data:\n",
        "    df = pd.DataFrame(user_data)\n",
        "    df.to_csv(\"users.csv\", index=False)\n",
        "    print(\"Data saved to users.csv\")\n",
        "else:\n",
        "    print(\"No data to save.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "import time\n",
        "\n",
        "# GitHub API token for authentication\n",
        "TOKEN = \"My_Token\"\n",
        "HEADERS = {\"Authorization\": f\"token {TOKEN}\"}\n",
        "\n",
        "# Load unique users from users.csv\n",
        "users_df = pd.read_csv(\"users.csv\")\n",
        "unique_logins = users_df['login'].unique()  # Ensure only unique logins\n",
        "repository_data = []\n",
        "\n",
        "# Loop through each unique user login\n",
        "for login in unique_logins:\n",
        "    page = 1\n",
        "    repo_count = 0\n",
        "\n",
        "    while repo_count < 500:\n",
        "        # Fetch repositories for the user, sorted by most recently pushed\n",
        "        repo_url = f\"https://api.github.com/users/{login}/repos\"\n",
        "        params = {\n",
        "            \"sort\": \"pushed\",\n",
        "            \"per_page\": 100,\n",
        "            \"page\": page\n",
        "        }\n",
        "        response = requests.get(repo_url, headers=HEADERS, params=params)\n",
        "\n",
        "        # Check for errors in response\n",
        "        if response.status_code != 200:\n",
        "            print(\"Error:\", response.status_code, response.text)\n",
        "            break\n",
        "\n",
        "        repos = response.json()\n",
        "        if not repos:\n",
        "            break  # Stop if no more repositories\n",
        "\n",
        "        # Process each repository\n",
        "        for repo in repos:\n",
        "            if repo_count >= 500:\n",
        "                break  # Stop after collecting 500 repositories\n",
        "\n",
        "            repository_data.append({\n",
        "                \"login\": login,\n",
        "                \"full_name\": repo.get(\"full_name\", \"\"),\n",
        "                \"created_at\": repo.get(\"created_at\", \"\"),\n",
        "                \"stargazers_count\": repo.get(\"stargazers_count\", 0),\n",
        "                \"watchers_count\": repo.get(\"watchers_count\", 0),\n",
        "                \"language\": repo.get(\"language\", \"\"),\n",
        "                \"has_projects\": \"true\" if repo.get(\"has_projects\") else \"false\",\n",
        "                \"has_wiki\": \"true\" if repo.get(\"has_wiki\") else \"false\",\n",
        "                \"license_name\": repo[\"license\"][\"key\"] if repo.get(\"license\") else \"\"\n",
        "            })\n",
        "            repo_count += 1\n",
        "\n",
        "        page += 1\n",
        "        time.sleep(1)  # Optional: sleep to avoid rate limiting\n",
        "\n",
        "# Convert list of dictionaries to DataFrame\n",
        "df_repos = pd.DataFrame(repository_data)\n",
        "\n",
        "# Save DataFrame to repositories.csv\n",
        "df_repos.to_csv(\"repositories.csv\", index=False)\n",
        "print(\"Data saved to repositories.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7y1sEmYP0Kxi",
        "outputId": "5e07390b-61a5-4ec8-b672-5a52009fcb33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data saved to repositories.csv\n"
          ]
        }
      ]
    }
  ]
}