# -*- coding: utf-8 -*-
"""Ajay_TDS-1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1A8qixcSBN85BDe3xKkKGkPY-0FxqwLLo

Q1. Who are the top 5 users in Austin with the highest number of followers? List their login in order, comma-separated.
"""

import pandas as pd

# Load the users dataset
users_df = pd.read_csv('users.csv')  # Replace with the path to your 'users.csv' file

# Filter for users with location in Austin and over 100 followers
austin_users = users_df[(users_df['location'].str.contains('Austin', case=False)) & (users_df['followers'] > 100)]

# Sort by followers in descending order and get the top 5 users
top_users = austin_users.sort_values(by='followers', ascending=False).head(5)

# Get their logins as a comma-separated list
top_logins = ', '.join(top_users['login'].tolist())
print(f"Top 5 users in Austin by followers: {top_logins}")

"""Q2. Who are the 5 earliest registered GitHub users in Austin? List their login in ascending order of created_at, comma-separated.
Users
"""

# Filter for users with location in Austin
austin_users = users_df[users_df['location'].str.contains('Austin', case=False)]

# Convert 'created_at' column to datetime format
austin_users['created_at'] = pd.to_datetime(austin_users['created_at'])

# Sort by 'created_at' in ascending order and get the top 5 earliest users
earliest_users = austin_users.sort_values(by='created_at', ascending=True).head(5)

# Get their logins as a comma-separated list
earliest_logins = ', '.join(earliest_users['login'].tolist())
print(f"5 earliest registered GitHub users in Austin: {earliest_logins}")

"""Q3. What are the 3 most popular license among these users? Ignore missing licenses. List the license_name in order, comma-separated.
Licenses
"""

repos_df = pd.read_csv('repositories.csv')

# Filter out rows with missing licenses
repos_with_licenses = repos_df[repos_df['license_name'].notna()]

# Count occurrences of each license and get the top 3
top_licenses = repos_with_licenses['license_name'].value_counts().head(3)

# Get the license names as a comma-separated list
top_licenses_list = ', '.join(top_licenses.index.tolist())
print(f"3 most popular licenses: {top_licenses_list}")

"""Q4. Which company do the majority of these developers work at?
Company (cleaned up as explained above)
"""

users_df['company'] = users_df['company'].str.strip().str.lstrip('@').str.upper()

# Filter out any missing values in 'company'
users_with_company = users_df[users_df['company'].notna()]

# Find the most common company among these users
top_company = users_with_company['company'].value_counts().idxmax()

print(f"The company with the majority of these developers is: {top_company}")

"""Q5. Which programming language is most popular among these users?
Language
"""

repos_with_language = repos_df[repos_df['language'].notna() & (repos_df['language'] != '')]

# Find the most common programming language
top_language = repos_with_language['language'].value_counts().idxmax()

print(f"The most popular programming language among these users is: {top_language}")

"""Q6. Which programming language is the second most popular among users who joined after 2020?
Language
"""

import pandas as pd

# Load the CSV files
users_df = pd.read_csv("users.csv")
repositories_df = pd.read_csv("repositories.csv")

# Step 1: Filter users who joined after 2020
users_after_2020 = users_df[users_df['created_at'] > '2020-01-01']

# Step 2: Filter repositories for these users
# Select usernames of users who joined after 2020
user_logins_after_2020 = set(users_after_2020['login'])

# Filter repositories based on these usernames
filtered_repos = repositories_df[repositories_df['login'].isin(user_logins_after_2020)]

# Step 3: Count occurrences of each language
language_counts = filtered_repos['language'].value_counts()

# Step 4: Get the second most popular language
if len(language_counts) > 1:
    second_most_popular_language = language_counts.index[1]
    print("The second most popular language is:", second_most_popular_language)
else:
    print("Not enough languages to determine the second most popular.")

"""Q7. Which language has the highest average number of stars per repository?
Language
"""

repositories_df = repositories_df.dropna(subset=['language', 'stargazers_count'])

# Group by language and calculate the average number of stars for each language
language_star_averages = repositories_df.groupby('language')['stargazers_count'].mean()

# Find the language with the highest average star count
top_language = language_star_averages.idxmax()
top_average_stars = language_star_averages.max()

print(f"The language with the highest average stars per repository is: {top_language} with an average of {top_average_stars:.2f} stars.")

"""Q8. Let's define leader_strength as followers / (1 + following). Who are the top 5 in terms of leader_strength? List their login in order, comma-separated.
User login
"""

users_df['leader_strength'] = users_df['followers'] / (1 + users_df['following'])

# Sort by leader_strength in descending order and select the top 5 users
top_5_users = users_df.nlargest(5, 'leader_strength')

# Extract the login names of the top 5 users
top_5_logins = top_5_users['login'].tolist()

# Output the result as comma-separated values
print("Top 5 users by leader_strength:", ", ".join(top_5_logins))

"""Q9. What is the correlation between the number of followers and the number of public repositories among users in Austin?
Correlation between followers and repos (to 3 decimal places, e.g. 0.123 or -0.123)
"""

users_df = pd.read_csv("users.csv")

# Filter users based in Austin
austin_users = users_df[users_df['location'].str.contains("Austin", case=False, na=False)]

# Calculate the correlation between followers and public_repos
correlation = austin_users['followers'].corr(austin_users['public_repos'])

# Print the correlation rounded to 3 decimal places
print(f"Correlation between followers and public_repos for Austin users: {correlation:.3f}")

"""Q10. Does creating more repos help users get more followers? Using regression, estimate how many additional followers a user gets per additional public repository.
Regression slope of followers on repos (to 3 decimal places, e.g. 0.123 or -0.123)
"""

from sklearn.linear_model import LinearRegression

# Load the users CSV file
users_df = pd.read_csv("users.csv")

# Prepare the data for regression
X = users_df[['public_repos']]  # Predictor variable (number of repositories)
y = users_df['followers']        # Response variable (number of followers)

# Initialize and fit the linear regression model
model = LinearRegression()
model.fit(X, y)

# Get the slope (coefficient) of the regression line
slope = model.coef_[0]

# Print the slope rounded to 3 decimal places
print(f"Estimated followers gained per additional repository: {slope:.3f}")

"""Q11. Do people typically enable projects and wikis together? What is the correlation between a repo having projects enabled and having wiki enabled?
Correlation between projects and wiki enabled (to 3 decimal places, e.g. 0.123 or -0.123)
"""

import pandas as pd

# Load the repositories CSV file
repositories_df = pd.read_csv("repositories.csv")

# Calculate the correlation between has_projects and has_wiki
correlation = repositories_df['has_projects'].corr(repositories_df['has_wiki'])

# Print the correlation rounded to 3 decimal places
print(f"Correlation between projects enabled and wiki enabled: {correlation:.3f}")

"""Q12. Do hireable users follow more people than those who are not hireable?
Average of following per user for hireable=true minus the average following for the rest (to 3 decimal places, e.g. 12.345 or -12.345)
"""

def analyze_following_difference(users_csv_path='users.csv'):
    # Read the data
    df = pd.read_csv(users_csv_path)

    # Calculate average following for hireable users
    hireable_following = df[df['hireable'] == True]['following'].mean()

    # Calculate average following for non-hireable users
    non_hireable_following = df[df['hireable'] != True]['following'].mean()

    # Calculate the difference rounded to 3 decimal places
    difference = round(hireable_following - non_hireable_following, 3)

    # Print debug information
    print(f"Number of hireable users: {len(df[df['hireable'] == True])}")
    print(f"Number of non-hireable users: {len(df[df['hireable'] != True])}")
    print(f"Average following for hireable users: {hireable_following:.3f}")
    print(f"Average following for non-hireable users: {non_hireable_following:.3f}")

    return difference

# Calculate the difference
result = analyze_following_difference()
print(f"\nDifference in average following: {result:.3f}")

"""Q13. Some developers write long bios. Does that help them get more followers? What's the impact of the length of their bio (in Unicode words, split by whitespace) with followers? (Ignore people without bios)
Regression slope of followers on bio word count (to 3 decimal places, e.g. 12.345 or -12.345)
"""

from sklearn.linear_model import LinearRegression

# Load the users CSV file
users_df = pd.read_csv("users.csv")

# Filter out users without bios
users_with_bios = users_df[users_df['bio'].notna()]

# Calculate the length of each bio in words (Unicode words)
users_with_bios['bio_word_count'] = users_with_bios['bio'].str.split().str.len()

# Prepare the data for regression
X = users_with_bios[['bio_word_count']]  # Predictor variable (length of bio in words)
y = users_with_bios['followers']          # Response variable (number of followers)

# Initialize and fit the linear regression model
model = LinearRegression()
model.fit(X, y)

# Get the slope (coefficient) of the regression line
slope = model.coef_[0]

# Print the slope rounded to 3 decimal places
print(f"Impact of bio length on followers (slope): {slope:.3f}")

"""Q14. Who created the most repositories on weekends (UTC)? List the top 5 users' login in order, comma-separated
Users login
"""

# Convert the created_at column to datetime
repositories_df['created_at'] = pd.to_datetime(repositories_df['created_at'])

# Filter for weekend days (Saturday = 5, Sunday = 6)
weekend_repos = repositories_df[repositories_df['created_at'].dt.dayofweek >= 5]

# Count the number of repositories created by each user on weekends
top_users = weekend_repos['login'].value_counts().nlargest(5)

# Extract the top 5 user logins
top_5_logins = top_users.index.tolist()

# Print the top 5 users' logins as a comma-separated string
print("Top 5 users who created the most repositories on weekends:", ", ".join(top_5_logins))

"""Q15. Do people who are hireable share their email addresses more often?
[fraction of users with email when hireable=true] minus [fraction of users with email for the rest] (to 3 decimal places, e.g. 0.123 or -0.123)
"""

def analyze_email_sharing(users_csv_path='users.csv'):
    # Read the complete CSV file
    df = pd.read_csv(users_csv_path)

    # Convert email column to boolean (True if email exists, False if NaN or empty)
    df['has_email'] = df['email'].notna() & (df['email'] != '')

    # Calculate for hireable users
    hireable_mask = df['hireable'] == True
    if hireable_mask.any():
        hireable_email_fraction = df[hireable_mask]['has_email'].mean()
    else:
        hireable_email_fraction = 0

    # Calculate for non-hireable users
    non_hireable_mask = df['hireable'] != True
    if non_hireable_mask.any():
        non_hireable_email_fraction = df[non_hireable_mask]['has_email'].mean()
    else:
        non_hireable_email_fraction = 0

    # Calculate difference and round to 3 decimal places
    difference = round(hireable_email_fraction - non_hireable_email_fraction, 3)

    # Print debug information
    print(f"Total users: {len(df)}")
    print(f"Hireable users with email: {df[hireable_mask]['has_email'].sum()}/{hireable_mask.sum()}")
    print(f"Non-hireable users with email: {df[non_hireable_mask]['has_email'].sum()}/{non_hireable_mask.sum()}")
    print(f"Hireable fraction: {hireable_email_fraction:.3f}")
    print(f"Non-hireable fraction: {non_hireable_email_fraction:.3f}")

    return difference

# Read and analyze the complete dataset
result = analyze_email_sharing()
print(f"\nFinal result: {result:.3f}")

"""Q16. Let's assume that the last word in a user's name is their surname (ignore missing names, trim and split by whitespace.) What's the most common surname? (If there's a tie, list them all, comma-separated, alphabetically)
Most common surname(s)
"""

from collections import Counter

# Load the users CSV file
users_df = pd.read_csv("users.csv")

# Filter out missing names and extract surnames
users_df['surname'] = users_df['name'].str.strip().str.split().str[-1]

# Count the occurrences of each surname, ignoring missing surnames
surname_counts = Counter(users_df['surname'].dropna())

# Find the maximum occurrence count
max_count = max(surname_counts.values())

# Get all surnames with the maximum occurrence count
most_common_surnames = [surname for surname, count in surname_counts.items() if count == max_count]

# Sort surnames alphabetically
most_common_surnames.sort()

# Print the result as a comma-separated string
print("Most common surnames:", ", ".join(most_common_surnames))